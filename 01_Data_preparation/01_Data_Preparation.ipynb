{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d638aad-b212-476a-8264-0cab8b5e5cfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ccea49-85c3-4ad6-81ef-c3d209127ec7",
   "metadata": {},
   "source": [
    "Use ```reader()``` method from csv package to read ```.csv``` files.\n",
    "<br />\n",
    "Use ```os.path.join()``` from os package to join directory names, because paths names are different in Windows and Linux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23017f45-b276-43f8-ad05-971049f10926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c9f16d-f2db-4347-a78f-c385fdcf6336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filename):\n",
    "    file = open(filename, \"r\")\n",
    "    lines = reader(file)\n",
    "    dataset  = list(lines)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7cb754-06ab-4343-9328-ecae1857773b",
   "metadata": {},
   "source": [
    "Listing available datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a924ea-4542-4098-a54c-dc1235ab7796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_banknote_authentication.txt\n",
      "iris.csv\n",
      "pima-indians-diabetes.csv\n",
      "sonar.all-data\n",
      "winequality-white.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbac9853-7102-4a17-b9e5-5a2b75a6270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data file ..\\datasets\\pima-indians-diabetes.csv with 768 rows and 9 columns\n",
      "\n",
      "\n",
      "Sample data :\n",
      "['6', '148', '72', '35', '0', '33.6', '0.627', '50', '1']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'pima-indians-diabetes.csv'\n",
    "data_path = os.path.join('..', 'datasets', data_name)\n",
    "dataset = load_csv(data_path)\n",
    "\n",
    "print(f'Loaded data file {data_path} with {len(dataset)} rows and {len(dataset[0])} columns')\n",
    "print('\\n')\n",
    "print('Sample data :')\n",
    "print(f'{dataset[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a9e991-e2c9-4e42-893a-3e5756bdcce6",
   "metadata": {},
   "source": [
    "Convert required string columns to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4186b1e-3d36-436f-890c-2e81b721a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_str_to_float(dataset, col):\n",
    "    for row in dataset:\n",
    "        row[col] = float(row[col].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f7e1bd8-8f5f-44e2-b549-a044329a486e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0, 148.0, 72.0, 35.0, '0', '33.6', '0.627', '50', '1']\n"
     ]
    }
   ],
   "source": [
    "col_to_float = [0, 1, 2, 3]\n",
    "for col in col_to_float:\n",
    "    col_str_to_float(dataset, col)\n",
    "\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378438ca-14a1-4c0e-a270-c4000b485fee",
   "metadata": {},
   "source": [
    "Convert class column to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3110096a-10a7-4068-8d28-70e3b400a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_str_to_int(dataset, col):\n",
    "    classes = set([row[col] for row in dataset])\n",
    "    lookup = {v : i for i, v in enumerate(classes)}\n",
    "    for row in dataset:\n",
    "        row[col] = lookup[row[col]]\n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f51b4b4-ff1a-45ca-96b1-ba9679fb8135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data file ..\\datasets\\iris.csv with 150 rows and 5 columns\n",
      "\n",
      "\n",
      "Sample data :\n",
      "['5.1', '3.5', '1.4', '.2', 'Setosa']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'iris.csv'\n",
    "data_path = os.path.join('..', 'datasets', data_name)\n",
    "dataset = load_csv(data_path)\n",
    "\n",
    "print(f'Loaded data file {data_path} with {len(dataset)} rows and {len(dataset[0])} columns')\n",
    "print('\\n')\n",
    "print('Sample data :')\n",
    "print(f'{dataset[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "450f3522-b22f-42bb-be76-28cfcee0fb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before conversion :\n",
      "['5.1', '3.5', '1.4', '.2', 'Setosa']\n",
      "After conversion :\n",
      "[5.1, 3.5, 1.4, 0.2, 0]\n",
      "lookup dictionary of classes : {'Setosa': 0, 'Virginica': 1, 'Versicolor': 2}\n"
     ]
    }
   ],
   "source": [
    "print('Before conversion :')\n",
    "print(dataset[0])\n",
    "col_to_float = [0, 1, 2, 3]\n",
    "for col in col_to_float:\n",
    "    col_str_to_float(dataset, col)\n",
    "\n",
    "col_to_int = 4\n",
    "lookup = col_str_to_int(dataset, col_to_int)\n",
    "\n",
    "print('After conversion :')\n",
    "print(dataset[0])\n",
    "print(f'lookup dictionary of classes : {lookup}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3467a51c-7cf0-44c8-8a4f-f83c0ecb6966",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148269a4-3763-4499-9253-69d6c051ed75",
   "metadata": {},
   "source": [
    "### Normalize Data\n",
    "\n",
    "Normalization can refer to different techniques depending on context. Here, we use normalization\n",
    "to refer to rescaling an input variable to the range between 0 and 1. Normalization requires\n",
    "that you know the minimum and maximum values for each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcc281c8-6322-43c6-aead-f0b04a32cbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data file ..\\datasets\\iris.csv with 150 rows and 5 columns\n",
      "\n",
      "\n",
      "Sample data :\n",
      "['5.1', '3.5', '1.4', '.2', 'Setosa']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'iris.csv'\n",
    "data_path = os.path.join('..', 'datasets', data_name)\n",
    "dataset = load_csv(data_path)\n",
    "\n",
    "print(f'Loaded data file {data_path} with {len(dataset)} rows and {len(dataset[0])} columns')\n",
    "print('\\n')\n",
    "print('Sample data :')\n",
    "print(f'{dataset[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0b30bb0-0335-4987-b3ea-37daf4bdd9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before conversion :\n",
      "['5.1', '3.5', '1.4', '.2', 'Setosa']\n",
      "After conversion :\n",
      "[5.1, 3.5, 1.4, 0.2, 0]\n",
      "lookup dictionary of classes : {'Setosa': 0, 'Virginica': 1, 'Versicolor': 2}\n"
     ]
    }
   ],
   "source": [
    "print('Before conversion :')\n",
    "print(dataset[0])\n",
    "col_to_float = [0, 1, 2, 3]\n",
    "for col in col_to_float:\n",
    "    col_str_to_float(dataset, col)\n",
    "\n",
    "col_to_int = 4\n",
    "lookup = col_str_to_int(dataset, col_to_int)\n",
    "\n",
    "print('After conversion :')\n",
    "print(dataset[0])\n",
    "print(f'lookup dictionary of classes : {lookup}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2494762c-306a-4c6b-b0b9-108caa49186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_col(dataset, col):\n",
    "    values = [row[col] for row in dataset]\n",
    "    min_val = min(values)\n",
    "    max_val = max(values)\n",
    "    for row in dataset:\n",
    "        row[col] = (row[col] - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deaff8b6-97b5-4a8d-8aaf-9be6a560fdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22222222222222213, 0.6249999999999999, 0.06779661016949151, 0.04166666666666667, 0]\n"
     ]
    }
   ],
   "source": [
    "cols_to_norm = [0, 1, 2, 3]\n",
    "for col in cols_to_norm:\n",
    "    normalize_col(dataset, col)\n",
    "\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d4c5e1-41a2-4a55-991c-6912b40b42bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0508d3bc-e1e1-469e-ab9a-fd4b5f18a9bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Standardize Data\n",
    "Standardization is a rescaling technique that refers to centering the distribution of the data on the value 0 and the standard deviation to the value 1. Together, the mean and the standard deviation can be used to summarize a normal distribution, also called the Gaussian distribution or bell curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "009de947-fca7-4c16-9042-0ba8c8319d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data file ..\\datasets\\iris.csv with 150 rows and 5 columns\n",
      "\n",
      "\n",
      "Sample data :\n",
      "['5.1', '3.5', '1.4', '.2', 'Setosa']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'iris.csv'\n",
    "data_path = os.path.join('..', 'datasets', data_name)\n",
    "dataset = load_csv(data_path)\n",
    "\n",
    "print(f'Loaded data file {data_path} with {len(dataset)} rows and {len(dataset[0])} columns')\n",
    "print('\\n')\n",
    "print('Sample data :')\n",
    "print(f'{dataset[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6578962-94c0-4d30-9386-2d94297d54ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before conversion :\n",
      "['5.1', '3.5', '1.4', '.2', 'Setosa']\n",
      "After conversion :\n",
      "[5.1, 3.5, 1.4, 0.2, 0]\n",
      "lookup dictionary of classes : {'Setosa': 0, 'Virginica': 1, 'Versicolor': 2}\n"
     ]
    }
   ],
   "source": [
    "print('Before conversion :')\n",
    "print(dataset[0])\n",
    "col_to_float = [0, 1, 2, 3]\n",
    "for col in col_to_float:\n",
    "    col_str_to_float(dataset, col)\n",
    "\n",
    "col_to_int = 4\n",
    "lookup = col_str_to_int(dataset, col_to_int)\n",
    "\n",
    "print('After conversion :')\n",
    "print(dataset[0])\n",
    "print(f'lookup dictionary of classes : {lookup}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68d42f69-bc25-467c-a704-bccfa47030e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_col(dataset, col):\n",
    "    values = [row[col] for row in dataset]\n",
    "    mean = sum(values) / len(values)\n",
    "    std = sqrt(sum([pow(_val - mean, 2) for _val in values]) / (len(values) - 1))\n",
    "    for row in dataset:\n",
    "        row[col] = (row[col] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23004a8f-597a-4c4f-8e17-cdf73d6dd493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8976738791967672, 1.0156019907136327, -1.3357516342415212, -1.3110521482051314, 0]\n"
     ]
    }
   ],
   "source": [
    "cols_to_std = [0, 1, 2, 3]\n",
    "for col in cols_to_std:\n",
    "    standardize_col(dataset, col)\n",
    "\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1941e5a-8567-405b-ada8-09be8135b793",
   "metadata": {
    "tags": []
   },
   "source": [
    "### When to Normalize and Standardize\n",
    "Standardization is a scaling technique that assumes your data conforms to a normal distribution. If a given data attribute is normal or close to normal, this is probably the scaling method to use. It is good practice to record the summary statistics used in the standardization process so that you can apply them when standardizing data in the future that you may want to use with your model. Normalization is a scaling technique that does not assume any specific distribution. If your data is not normally distributed, consider normalizing it prior to applying your machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203cf55e-1e41-40dc-9e06-3304bf10e682",
   "metadata": {},
   "source": [
    "## Train and Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cbda07-f780-456e-9f25-6cb35fa149b2",
   "metadata": {},
   "source": [
    "Splitting data into train and test sets. Model will be trained on training set and later model will be evaluated on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "958a04a2-659b-473a-84e2-a3ad1b8f5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed = 1234\n",
    "def train_test_split(dataset, split_ratio):\n",
    "    train = list()\n",
    "    train_size = split_ratio * len(dataset)\n",
    "    dataset_copy = list(dataset)\n",
    "    while len(train) < train_size:\n",
    "        index = random.randrange(len(dataset_copy))\n",
    "        train.append(dataset_copy.pop(index))\n",
    "    return train, dataset_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e995a14-4233-4644-a5d2-75727470138a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample : \n",
      "[-0.29385736852629735, -0.1315388120502617, 0.19373496985182176, 0.13206729444894824, 2]\n",
      "Test sample : \n",
      "[-0.8976738791967672, 1.0156019907136327, -1.3357516342415212, -1.3110521482051314, 0]\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataset, split_ratio = 0.7)\n",
    "\n",
    "print('Training sample : ')\n",
    "print(train[0])\n",
    "print('Test sample : ')\n",
    "print(test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2abe212-c305-47ec-8f25-e5c6bf3d58cd",
   "metadata": {},
   "source": [
    "## k-fold Crossvalidation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521141f3-2dbf-4f1b-a34f-61e1280d6269",
   "metadata": {},
   "source": [
    "k-fold Cross validation help in improve model accuracy. Model will be trained on k-1 folds and evaluated on kth fold, this will happen on iteration. In every iteration, kth fold will get changed. We select that model which will have least accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3ebfe22-ff8a-4f2b-9f53-d7061327ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed = 1234\n",
    "def cross_validation_split(dataset, n_folds = 3):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset_copy) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = random.randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "991c9925-0dff-448e-8a44-10da7a67bae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.5014903898672372, 0.32731750905529644, -1.3357516342415212, -1.3110521482051314, 0], [-1.5014903898672372, 0.09788934850251736, -1.279103982238064, -1.3110521482051314, 0], [-0.8976738791967672, 1.0156019907136327, -1.3357516342415212, -1.1798594716002149, 0], [-1.6222536920013308, -1.737535935919714, -1.3923992862449786, -1.1798594716002149, 0], [0.3099591421441726, -0.1315388120502617, 0.6469161858794794, 0.7880306774735298, 1], [-0.4146206706603909, -1.049251454261377, 0.3636779258621936, 0.0008746178440318052, 2], [0.6722490485464554, 0.09788934850251736, 0.9868020979002221, 0.7880306774735298, 1], [-1.259963785599049, -0.1315388120502617, -1.3357516342415212, -1.1798594716002149, 0], [-0.1730940663922027, 3.080455435688643, -1.279103982238064, -1.0486667949952986, 0], [-0.29385736852629735, -0.1315388120502617, 0.19373496985182176, 0.13206729444894824, 2], [0.5514857464123608, -1.278679614814156, 0.6469161858794794, 0.3944526476587808, 2], [-0.29385736852629735, -0.5903951331558198, 0.6469161858794794, 1.0504160306833623, 1], [-0.5353839727944845, 0.7861738301608535, -1.279103982238064, -1.0486667949952986, 0], [0.5514857464123608, 0.5567456696080745, 1.270040357917508, 1.706379413707944, 1], [-0.8976738791967672, 1.7038864723719687, -1.2224563302346068, -1.3110521482051314, 0], [-1.0184371813308608, 0.7861738301608535, -1.279103982238064, -1.3110521482051314, 0], [-0.29385736852629735, -1.278679614814156, 0.0804396658449076, -0.13031805876088434, 2], [0.18919584001007905, -0.1315388120502617, 0.590268533876022, 0.7880306774735298, 1], [1.5175921634851124, -0.1315388120502617, 1.213392705914051, 1.1816087072882788, 1], [-1.1392004834649543, 1.2450301512664117, -1.3357516342415212, -1.4422448248100475, 0], [-1.1392004834649543, -0.1315388120502617, -1.3357516342415212, -1.3110521482051314, 0], [-1.7430169941354243, -0.1315388120502617, -1.3923992862449786, -1.3110521482051314, 0], [1.6383554656192072, 1.2450301512664117, 1.3266880099209648, 1.706379413707944, 1], [2.242171976289677, -0.5903951331558198, 1.666573921941708, 1.0504160306833623, 1], [0.5514857464123608, -0.8198232937085979, 0.6469161858794794, 0.7880306774735298, 1], [0.5514857464123608, 0.5567456696080745, 0.533620881872565, 0.5256453242636973, 2], [-1.0184371813308608, 0.7861738301608535, -1.2224563302346068, -1.0486667949952986, 0], [-0.8976738791967672, 1.0156019907136327, -1.3357516342415212, -1.3110521482051314, 0], [-1.1392004834649543, -1.508107775366935, -0.2594462461758354, -0.2615107353658008, 2], [-0.05233076425810914, -0.8198232937085979, 0.7602114898863933, 0.919223354078446, 1], [1.2760655592169254, 0.09788934850251736, 0.6469161858794794, 0.3944526476587808, 2], [-1.863780296269519, -0.1315388120502617, -1.5056945902518926, -1.4422448248100475, 0], [-0.656147274928579, 1.4744583118191907, -1.279103982238064, -1.3110521482051314, 0], [2.4836985805578653, 1.7038864723719687, 1.4966309659313366, 1.0504160306833623, 1], [-0.1730940663922027, -0.5903951331558198, 0.42032557786565056, 0.13206729444894824, 2], [-0.05233076425810914, -0.8198232937085979, 0.7602114898863933, 0.919223354078446, 1], [-0.05233076425810914, -0.5903951331558198, 0.7602114898863933, 1.5751867371030275, 1]]\n"
     ]
    }
   ],
   "source": [
    "folds = cross_validation_split(dataset, n_folds = 4)\n",
    "\n",
    "print(folds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ee5a3a-4c15-47c5-9591-8ed37a18ea01",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b88f91-9dc7-4c7a-8d32-f2e17b5f5a6c",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "974bc9a3-20a5-475a-9ef3-6545e15be240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    if len(actual) == len(predicted):\n",
    "        for i in range(len(actual)):\n",
    "            if actual[i] == predicted[i]:\n",
    "                correct += 1\n",
    "        return correct * 100.0 / float(len(actual))\n",
    "    else:\n",
    "        return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "121bb62c-b965-45db-87a8-11c82e634e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.0\n"
     ]
    }
   ],
   "source": [
    "actual = [0,0,0,0,0,1,1,1,1,1]\n",
    "predicted = [0,1,0,0,0,1,0,1,1,1]\n",
    "accuracy = accuracy_metric(actual, predicted)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e692df6e-b479-4e04-811b-fff20194b08d",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3eaf4093-0130-4e38-ade3-d3756b79c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(actual, predicted):\n",
    "    classes = set(actual)\n",
    "    if len(actual) == len(predicted):\n",
    "        matrix = [[0 for x in range(len(classes))] for y in range(len(classes))]\n",
    "        lookup_dict = {v: k for k, v in enumerate(classes)}\n",
    "        for i in range(len(actual)):\n",
    "            x = lookup_dict[actual[i]]\n",
    "            y = lookup_dict[predicted[i]]\n",
    "            matrix[x][y] += 1\n",
    "        return [classes, matrix]\n",
    "    else:\n",
    "        return [classes, 'error']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f49fc470-9e39-4660-87a1-b81fc2127c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n",
      "[[3, 2], [1, 4]]\n"
     ]
    }
   ],
   "source": [
    "actual =  [0,0,0,0,0,1,1,1,1,1]\n",
    "predicted = [0,1,1,0,0,1,0,1,1,1]\n",
    "unique, matrix = confusion_matrix(actual, predicted)\n",
    "print(unique)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c578df5-a57b-4729-848e-ee2a9cce9607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
